{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Learns to Play Connect 4\n",
    "#### Jordan Yeomans - 2018\n",
    "\n",
    "## Part 5 - Building A Neural Network In Tensorflow\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "- Currently we have a code that can organise all of the recorded games of a random vs random bot playing. \n",
    "- We have stored all of the winning games and we now want to build a neural network that can predict the next move of the winning player, given a certain board.\n",
    "\n",
    "- We could use a high level framework like Keras for this, which I would recommend as something fun to do. It would certainly be faster. Personally, my aim is to become a world-class AI engineer/researcher and I believe becoming an expert at frameworks like Tensorflow is probably a better long term approach.\n",
    "\n",
    "So what's the approach?\n",
    "\n",
    "1. Load Data\n",
    "2. Perform a tiny amount of data processing\n",
    "3. Create Neural Network\n",
    "4. Create Loss Function and Evaluation Metric\n",
    "5. Train Network\n",
    "6. Evaluate the Network\n",
    "7. See if it works! (Part 6)\n",
    "\n",
    "#### Step 1 - Load Data\n",
    "\n",
    "At this point, I recorded around 12,000 individual games of the random vs random bot. I then used the code in Part 4 to organise them into a single array. Let's load that now\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jordan yeomans\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Data Shape = (55034, 6, 7):\n",
      "Output Data Shape = (55034, 7, 1):\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "# Copy and Paste from Previous Sections\n",
    "def plot_winner_board(board):\n",
    "    plt.figure()\n",
    "    for row in range(board.shape[0]):\n",
    "        for col in range(board.shape[1]):\n",
    "            if board[5-row][col] == 1:\n",
    "                plt.scatter(col, row, c='Blue', s=500, edgecolors='black')\n",
    "\n",
    "            if board[5-row][col] == -1:\n",
    "                plt.scatter(col, row, c='Black', s=500, edgecolors='black')\n",
    "    plt.grid()\n",
    "    plt.ylim(-1, 6)\n",
    "    plt.xlim(-1, 7)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "# NN Parameters\n",
    "lr = 0.0001\n",
    "epochs = 200\n",
    "val_split = 0.1\n",
    "eval_split = 0.05\n",
    "batch_size = 1024\n",
    "\n",
    "# Folder Paths\n",
    "data_load_folder = 'C:/Users/Jordan Yeomans/Documents/GitHub/RiddlesIO/four_in_a_row/Data/Processed_Data/Random_vs_Random/'\n",
    "nn_save_folder = 'C:/Users/Jordan Yeomans/Documents/GitHub/RiddlesIO/four_in_a_row/NeuralNetworks/AI_Bot_Version_1/'\n",
    "\n",
    "# Load Data\n",
    "move_history_input = np.load(data_load_folder + 'input_data.npy')\n",
    "move_history_output = np.load(data_load_folder + 'output_data.npy')\n",
    "\n",
    "# Check Number Of Samples\n",
    "print('Input Data Shape = {}:'.format(move_history_input.shape))\n",
    "print('Output Data Shape = {}:'.format(move_history_output.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2 - Data Processing\n",
    "\n",
    "Although we have all of the data in a single file, we need to do a tiny bit of data processing. \n",
    "\n",
    "1. We need to remove the last dimension of the output data. We didn't really need to include this in the first place, but since we did it's easy to remove\n",
    "2. We need to split the data into a Training set, Validation set and Evaluation set\n",
    "\n",
    "The training set will use used by the back propogation algorithm to learn what weights/biases in the network reduce the loss function.\n",
    "\n",
    "The Validation set will be used to ensure that \"un-seen\" data is also being learned on\n",
    "\n",
    "Finally, we keep some data as an evaluation set for a final check so ensure we haven't designed an architecture or over optimised hyperparameters to bias a result that only works on the validation set.\n",
    "\n",
    "To split the data, we will make a function that we can use again in the future:\n",
    "\n",
    "1. Calculate the number of training/validation and evaluation samples\n",
    "2. Create an array from 0 -> total number of samples\n",
    "3. Randomly shuffle the index's (Just the array we created, not the actual data)\n",
    "4. Assign training/validation/evaluation index's (Notice these are shuffled index's)\n",
    "5. Create Training/Validation/Evaluation Data by assigning the data from Move_History at each index\n",
    "6. Print the results as a check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Samples = 46780, Validation Samples = 5503, Evaluation Samples = 2751\n",
      "\n",
      "Example Output #9:\n",
      "  [0. 1. 0. 0. 0. 0. 0.]\n",
      "\n",
      "Example Input #9:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reshape output to shape (7, )\n",
    "move_history_output = move_history_output.reshape(move_history_output.shape[0], move_history_output.shape[1])\n",
    "\n",
    "\n",
    "def split_data(move_history_input, move_history_output, val_split, eval_split):\n",
    "\n",
    "    # Calculate the number of training/validation and evaluation samples\n",
    "    num_val = int(move_history_input.shape[0] * val_split)\n",
    "    num_eval = int(move_history_input.shape[0] * eval_split)\n",
    "    num_train = move_history_input.shape[0] - num_val - num_eval\n",
    "\n",
    "    # Create an array from 0 -> total number of samples\n",
    "    all_idx = np.arange(0, move_history_input.shape[0], 1)\n",
    "\n",
    "    # Randomly shuffle the index's (Just the array we created, not the actual data)\n",
    "    np.random.shuffle(all_idx)\n",
    "\n",
    "    # Assign training/validation/evaluation index's\n",
    "    train_idx = all_idx[:num_train]\n",
    "    val_idx = all_idx[num_train: num_train + num_val]\n",
    "    eval_idx = all_idx[num_train + num_val:]\n",
    "\n",
    "    # Create Training/Validation/Evaluation Data by assigning the data from Move_History at each index\n",
    "    train_input_data, train_output_data = move_history_input[train_idx], move_history_output[train_idx]\n",
    "    val_input_data, val_output_data = move_history_input[val_idx], move_history_output[val_idx]\n",
    "    eval_input_data, eval_output_data = move_history_input[eval_idx], move_history_output[eval_idx]\n",
    "    \n",
    "    print('Training Samples = {}, Validation Samples = {}, Evaluation Samples = {}'.format(train_input_data.shape[0], val_input_data.shape[0], eval_input_data.shape[0]))\n",
    "    return train_input_data, train_output_data, val_input_data, val_output_data, eval_input_data, eval_output_data\n",
    "\n",
    "\n",
    "# Split data into training, validation and evaluation\n",
    "train_in_data, train_out_data, val_in_data, val_out_data, eval_in_data, eval_out_data = split_data(move_history_input, move_history_output, val_split, eval_split)\n",
    "\n",
    "# Look at an example Input/Output\n",
    "example_num = 9\n",
    "print('\\nExample Output #{}:\\n  {}'.format(example_num, move_history_output[example_num]))\n",
    "print('\\nExample Input #{}:'.format(example_num))\n",
    "plot_winner_board(move_history_input[example_num])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that in this position, a token in the column with index = 1 is going to win the game. Definitely a good move!\n",
    "\n",
    "#### Step 3 - Create Neural Network\n",
    "\n",
    "Here is the fun part, making a neural network!\n",
    "\n",
    "Let's start simple with a 3-layer fully connected network. We will look into Convolutional Networks later but we will start with the basics for now\n",
    "\n",
    "1. Create some Placeholders:  x will be used to feed the input data, y will be used to feed the output data\n",
    "\n",
    "2. Create the Network: Follow the comments in the following code\n",
    "\n",
    "##### Activation Functions: \n",
    "\n",
    "We have added a Relu activation to the fully connected layers while not including any activation on the final layer. This is because the loss function we will be using internally applies an activation function and we don't want to apply it twice.\n",
    "\n",
    "##### What Is A Placeholder And What Is A Tensor?\n",
    "\n",
    "If you're searching for an official explaination for what a tensor is, it's best to Google an official tutorial. But the way I try to wrap my head around it is:\n",
    "\n",
    "- A tensor is kind of like a pre-allocated equation. We are just saying \"Hey computer, remember this equation. When I have some more information I want you calculate the result based on this equation\".\n",
    "\n",
    "\n",
    "- Remember, at this point we haven't told it what data to use. We have just said, \"When we do, here is what we want you to calculate\"\n",
    "\n",
    "\n",
    "- So how do the placeholders help? - Well, that is our way to telling the computer what sort of data it can expect when we finally give it that data. It's just a heads up - Something like: \"Im not sure how many input examples I'll give you (None), But they will all be of size (6,7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"input_placeholder:0\", shape=(?, 6, 7), dtype=float32)\n",
      "Tensor(\"output_placeholder:0\", shape=(?, 7), dtype=float32)\n",
      "Tensor(\"output/BiasAdd:0\", shape=(?, 7), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Create Placeholders\n",
    "x = tf.placeholder(tf.float32, shape=[None, 6, 7], name='input_placeholder')\n",
    "y = tf.placeholder(tf.float32, shape=[None, 7], name='output_placeholder')\n",
    "\n",
    "# Create Network\n",
    "nn = tf.layers.flatten(x, name='input')                 # Flatten Board\n",
    "nn = tf.layers.dense(nn, 256, activation=tf.nn.relu)    # Layer 1 - Fully Connected with 256 Nodes\n",
    "nn = tf.layers.dense(nn, 256, activation=tf.nn.relu)    # Layer 2 - Fully Connected with 256 Nodes\n",
    "nn = tf.layers.dense(nn, 256, activation=tf.nn.relu)    # Layer 3 - Fully Connected with 256 Nodes\n",
    "last_layer = tf.layers.dense(nn, 7, name='output')      # Output Layer\n",
    "\n",
    "\n",
    "print(x)\n",
    "print(y)\n",
    "print(last_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4 - Create A Loss Function, Optimiser & Evaluation Metric\n",
    "\n",
    "##### Loss Function:\n",
    "We have defined this problem as a classification problem: \"Which column should we place the token in\"\n",
    "\n",
    "This is something Neural Networks are really good at. We can use the softmax_cross_entropy_with_logits_v2 function built into tensorflow. Since it is asking for logits, the function wants raw output of the last layer without an activation applied.\n",
    "\n",
    "##### Optimiser:\n",
    "For the optimiser we are using the Adam optimiser\n",
    "\n",
    "##### Evaluation Metric:\n",
    "When we train the network, we will have the loss returned as a number. This doesn't really mean too much, we would like to know how accurate the predictions are. I got this from Stack Overflow a few weeks ago\n",
    "\n",
    "1. We create a tensor (Remember, this is like allocating an equation) to evaluate if the index of the argmax of the predicted output is equal to the argmax of the true output\n",
    "\n",
    "2. We create a tensor (New preset equation!) to evaluate the proportion of correct answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Loss Function\n",
    "loss_function = tf.nn.softmax_cross_entropy_with_logits_v2(logits=last_layer, labels=y)\n",
    "loss = tf.reduce_mean(loss_function)\n",
    "\n",
    "# Create Optimiser\n",
    "learning_step = tf.train.AdamOptimizer(lr)\n",
    "optimiser = learning_step.minimize(loss)\n",
    "\n",
    "# Create Accuracy Evaluation\n",
    "correct = tf.equal(tf.argmax(last_layer, axis=1), tf.argmax(y, axis=1))\n",
    "acc = tf.reduce_mean(tf.cast(correct, 'float'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are almost there! Just before we do, we need to be able to split our training data into batches. This is for a few reasons:\n",
    "\n",
    "1. There are practical limits to how many calculations your computer can do are once. This will depend on the type of data and how much memory you have\n",
    "2. There are performance increases by modifying the batch size. 1024 seems to be quite a common number, if you can fit that much into the memory\n",
    "\n",
    "Note: For Deep Learning you really want to have a good NVIDIA Graphics Card that can use the CUDA toolkit. I am using at GTX1080ti although you don't need to go that extreme! This project will probably work on a CPU, I haven't tried, let me know if it does"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_batches(train_in_data, train_out_data, batch_size):\n",
    "\n",
    "    num_batches = int(np.floor(train_in_data.shape[0]/batch_size))\n",
    "\n",
    "    train_in_batches = np.zeros((num_batches, batch_size, train_in_data.shape[1], train_in_data.shape[2]))\n",
    "    train_out_batches = np.zeros((num_batches, batch_size, train_out_data.shape[1]))\n",
    "\n",
    "    samples = np.arange(0, num_batches * batch_size, step=1)\n",
    "    np.random.shuffle(samples)\n",
    "\n",
    "    for i in range(train_in_batches.shape[0]):\n",
    "        start_num = i * batch_size\n",
    "        end_num = start_num + batch_size\n",
    "\n",
    "        batch_samples = samples[start_num:end_num]\n",
    "\n",
    "        train_in_batches[i] = train_in_data[batch_samples]\n",
    "        train_out_batches[i] = train_out_data[batch_samples]\n",
    "\n",
    "    return train_in_batches, train_out_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5 - Train Network\n",
    "\n",
    "Woohoo! The fun part! It's a bit of a mission to get this far!\n",
    "\n",
    "Let's make sure we can save the network. We can create a saver object with tf.train.Saver(). Also we will need to keep a copy of the best accuracy so we know to save the best network\n",
    "\n",
    "##### What is a Session?\n",
    "\n",
    "Again, if you're after an official explaination it's best to Google it. But here is my take:\n",
    "\n",
    "1. A session is an object that we use to run the network. While we are in the session, we can pass in variables and make calculations and the network will remember all of the parameters.\n",
    "2. As soon as we leave the session, all parameters are forgotten. So it is the session object that is storing the parameters being calculated.\n",
    "\n",
    "So what does that mean?\n",
    "\n",
    "- Any calculations need to be performed in a session\n",
    "- Any evaluations need to be performed in the \"same\" session (OR) Loaded from a saved session\n",
    "- As soon as you jump out of the session, the parameters (Weights/Biases etc) will be forgotten!!!! So we need to save them to disk\n",
    "\n",
    "##### What's Happening?\n",
    "\n",
    "1. Before we do anything, we need to initialise all variables.\n",
    "2. Iterate over all epochs\n",
    "3. For each epoch, we will split all of the training data into batches\n",
    "4. We can now iterate over each batch\n",
    "5. The magic line is *\n",
    "6. After all batches have been calculated we can evaluate the training and validation accuracy\n",
    "7. If we have improved the validation accuracy, we should save the model\n",
    "8. We can print the results every 50 epochs to keep a track of the progress\n",
    "9. After all epochs are complete, we can load the best model with saver.restore()\n",
    "10. We should evaluate the model using the evaluation data (It hasn't seen this yet!) to make sure the validation and evaluation prediction accuracy is similar\n",
    "\n",
    "###### * _, batch_cost = sess.run([optimiser, loss], feed_dict={x: train_in_batches[batch], y: train_out_batches[batch]})\n",
    "\n",
    "- The line above is running the network for 1 step. \n",
    "- During that step, it takes the current input batch and says \"Here is the x data you're expecting\". The output data for that batch is fed to the network in place of the y placeholder\n",
    "- This is repeated for each batch, before moving onto the next epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly Initialised Weight/Biases: Train Acc = 14.213%, Val Acc = 15.137%\n",
      "After 1 Epochs: Single Batch Cost = 1.849, Train Acc = 36.838%, Val Acc = 36.398%\n",
      "After 2 Epochs: Single Batch Cost = 1.721, Train Acc = 41.830%, Val Acc = 41.904%\n",
      "After 3 Epochs: Single Batch Cost = 1.642, Train Acc = 43.189%, Val Acc = 42.886%\n",
      "After 4 Epochs: Single Batch Cost = 1.503, Train Acc = 45.222%, Val Acc = 45.157%\n",
      "After 5 Epochs: Single Batch Cost = 1.484, Train Acc = 46.905%, Val Acc = 46.575%\n",
      "After 6 Epochs: Single Batch Cost = 1.455, Train Acc = 47.657%, Val Acc = 46.793%\n",
      "After 7 Epochs: Single Batch Cost = 1.381, Train Acc = 48.138%, Val Acc = 46.920%\n",
      "After 8 Epochs: Single Batch Cost = 1.338, Train Acc = 48.440%, Val Acc = 46.684%\n",
      "After 9 Epochs: Single Batch Cost = 1.359, Train Acc = 48.623%, Val Acc = 47.192%\n",
      "After 10 Epochs: Single Batch Cost = 1.329, Train Acc = 48.957%, Val Acc = 46.938%\n",
      "After 26 Epochs: Single Batch Cost = 1.256, Train Acc = 51.526%, Val Acc = 48.301%\n",
      "After 51 Epochs: Single Batch Cost = 1.199, Train Acc = 53.617%, Val Acc = 49.809%\n",
      "After 76 Epochs: Single Batch Cost = 1.149, Train Acc = 54.709%, Val Acc = 50.591%\n",
      "After 101 Epochs: Single Batch Cost = 1.153, Train Acc = 55.723%, Val Acc = 50.445%\n",
      "After 126 Epochs: Single Batch Cost = 1.116, Train Acc = 56.802%, Val Acc = 50.354%\n",
      "After 151 Epochs: Single Batch Cost = 1.109, Train Acc = 57.555%, Val Acc = 50.663%\n",
      "After 176 Epochs: Single Batch Cost = 1.080, Train Acc = 58.202%, Val Acc = 50.591%\n",
      "INFO:tensorflow:Restoring parameters from C:/Users/Jordan Yeomans/Documents/GitHub/RiddlesIO/four_in_a_row/NeuralNetworks/AI_Bot_Version_1/\n",
      "Evaluation Acc = 50.927%\n"
     ]
    }
   ],
   "source": [
    "# Create Saver\n",
    "saver = tf.train.Saver()\n",
    "best_acc = 0\n",
    "\n",
    "# Train Network\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # Initialise Variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    epoch_train_acc = sess.run(acc, feed_dict={x: train_in_data, y: train_out_data})\n",
    "    epoch_val_acc = sess.run(acc, feed_dict={x: val_in_data, y: val_out_data})\n",
    "    \n",
    "    print('Randomly Initialised Weight/Biases: Train Acc = {:.3f}%, Val Acc = {:.3f}%'.format(epoch_train_acc * 100, epoch_val_acc * 100))\n",
    "\n",
    "    # Iterate over all Epochs\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # Split training data into batches\n",
    "        train_in_batches, train_out_batches = split_into_batches(train_in_data, train_out_data, batch_size)\n",
    "\n",
    "        # Iterate over all batches\n",
    "        for batch in range(train_in_batches.shape[0]):\n",
    "\n",
    "            _, batch_cost = sess.run([optimiser, loss], feed_dict={x: train_in_batches[batch], y: train_out_batches[batch]})\n",
    "\n",
    "        # Evaluate Training and Validation Accuracy\n",
    "        epoch_train_acc = sess.run(acc, feed_dict={x: train_in_data, y: train_out_data})\n",
    "        epoch_val_acc = sess.run(acc, feed_dict={x: val_in_data, y: val_out_data})\n",
    "\n",
    "        # Save model if it is an improvement\n",
    "        if epoch_val_acc > best_acc:\n",
    "            best_acc = epoch_val_acc\n",
    "            saver.save(sess, nn_save_folder)\n",
    "        \n",
    "        # Print results every 50 epochs\n",
    "        if epoch < 10 or epoch % 25 == 0:\n",
    "            print('After {} Epochs: Single Batch Cost = {:.3f}, Train Acc = {:.3f}%, Val Acc = {:.3f}%'.format(epoch+1, batch_cost, epoch_train_acc * 100, epoch_val_acc * 100))\n",
    "\n",
    "    # Load Saved Session\n",
    "    saver.restore(sess, nn_save_folder)\n",
    "\n",
    "    # After Training, Check Evaluation Accuracy\n",
    "    eval_acc = sess.run(acc, feed_dict={x: eval_in_data, y: eval_out_data})\n",
    "    print('Evaluation Acc = {:.3f}%'.format(eval_acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Awesome! \n",
    "\n",
    "It seems to have learnt something! \n",
    "\n",
    "At first with randomly initialised weights we got an accuracy of around 14%. This makes sense since random guess has a 1/7 chance of being right = 14.3%\n",
    "\n",
    "As the network was trained we can see the accuracy increased to over 50%. It is going to be harder to get much more than this as in early game moves (say less than 4 pieces on the board) any move is probably equally good.\n",
    "\n",
    "It's also good to see the Validation and Evaluation predictions accuracy is similar. Also notice the training accuracy is close to 60%. Possibly the model is overfitting. We could experiment with techniques such as dropout but for now we will see if this bot works even a little bit!\n",
    "\n",
    "Let's see if we can put this into practice! Part 6: Implementing AI V1 is next \n",
    "\n",
    "As always, here is the complete code.\n",
    "\n",
    "Ignore the error at the bottom. It doesn't like it when you recreate a tensor with the same name!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Data Shape = (55034, 6, 7):\n",
      "Output Data Shape = (55034, 7, 1):\n",
      "[0. 1. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Samples = 46780, Validation Samples = 5503, Evaluation Samples = 2751\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Variable output/kernel already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"c:\\users\\jordan yeomans\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n  File \"c:\\users\\jordan yeomans\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"c:\\users\\jordan yeomans\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-81592bac8851>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[0mnn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m)\u001b[0m    \u001b[1;31m# Layer 2 - Fully Connected with 256 Nodes\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[0mnn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m)\u001b[0m    \u001b[1;31m# Layer 3 - Fully Connected with 256 Nodes\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m \u001b[0mlast_layer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'output'\u001b[0m\u001b[1;33m)\u001b[0m      \u001b[1;31m# Output Layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[1;31m# Define Loss Function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jordan yeomans\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\layers\\core.py\u001b[0m in \u001b[0;36mdense\u001b[1;34m(inputs, units, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, trainable, name, reuse)\u001b[0m\n\u001b[0;32m    251\u001b[0m                 \u001b[0m_scope\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m                 _reuse=reuse)\n\u001b[1;32m--> 253\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jordan yeomans\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    826\u001b[0m       \u001b[0mOutput\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \"\"\"\n\u001b[1;32m--> 828\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m   def _add_inbound_node(self,\n",
      "\u001b[1;32mc:\\users\\jordan yeomans\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    697\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'get_shape'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minput_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m             \u001b[0minput_shapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m           \u001b[1;31m# Note: not all sub-classes of Layer call Layer.__init__ (especially\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jordan yeomans\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\layers\\core.py\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    136\u001b[0m                                     \u001b[0mconstraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel_constraint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m                                     \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m                                     trainable=True)\n\u001b[0m\u001b[0;32m    139\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m       self.bias = self.add_variable('bias',\n",
      "\u001b[1;32mc:\\users\\jordan yeomans\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\u001b[0m in \u001b[0;36madd_variable\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, partitioner)\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[0mconstraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 546\u001b[1;33m             partitioner=partitioner)\n\u001b[0m\u001b[0;32m    547\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minit_graph\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jordan yeomans\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\training\\checkpointable.py\u001b[0m in \u001b[0;36m_add_variable_with_custom_getter\u001b[1;34m(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\u001b[0m\n\u001b[0;32m    434\u001b[0m     new_variable = getter(\n\u001b[0;32m    435\u001b[0m         \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 436\u001b[1;33m         **kwargs_for_getter)\n\u001b[0m\u001b[0;32m    437\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m     \u001b[1;31m# If we set an initializer and the variable processed it, tracking will not\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jordan yeomans\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\u001b[0m\n\u001b[0;32m   1315\u001b[0m       \u001b[0mpartitioner\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m       \u001b[0muse_resource\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcustom_getter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1317\u001b[1;33m       constraint=constraint)\n\u001b[0m\u001b[0;32m   1318\u001b[0m get_variable_or_local_docstring = (\n\u001b[0;32m   1319\u001b[0m     \"\"\"%s\n",
      "\u001b[1;32mc:\\users\\jordan yeomans\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\u001b[0m\n\u001b[0;32m   1077\u001b[0m           \u001b[0mpartitioner\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1078\u001b[0m           \u001b[0muse_resource\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcustom_getter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1079\u001b[1;33m           constraint=constraint)\n\u001b[0m\u001b[0;32m   1080\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1081\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[1;32mc:\\users\\jordan yeomans\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\u001b[0m\n\u001b[0;32m    423\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpartitioner\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m           \u001b[0mvalidate_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_resource\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 425\u001b[1;33m           constraint=constraint)\n\u001b[0m\u001b[0;32m    426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m   def _get_partitioned_variable(\n",
      "\u001b[1;32mc:\\users\\jordan yeomans\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[1;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint)\u001b[0m\n\u001b[0;32m    392\u001b[0m           \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m           use_resource=use_resource, constraint=constraint)\n\u001b[0m\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcustom_getter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jordan yeomans\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint)\u001b[0m\n\u001b[0;32m    731\u001b[0m                          \u001b[1;34m\"reuse=tf.AUTO_REUSE in VarScope? \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    732\u001b[0m                          \"Originally defined at:\\n\\n%s\" % (\n\u001b[1;32m--> 733\u001b[1;33m                              name, \"\".join(traceback.format_list(tb))))\n\u001b[0m\u001b[0;32m    734\u001b[0m       \u001b[0mfound_var\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_vars\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfound_var\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Variable output/kernel already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"c:\\users\\jordan yeomans\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n  File \"c:\\users\\jordan yeomans\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"c:\\users\\jordan yeomans\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "def split_data(move_history_input, move_history_output, val_split, eval_split):\n",
    "\n",
    "    # Calculate the number of training/validation and evaluation samples\n",
    "    num_val = int(move_history_input.shape[0] * val_split)\n",
    "    num_eval = int(move_history_input.shape[0] * eval_split)\n",
    "    num_train = move_history_input.shape[0] - num_val - num_eval\n",
    "\n",
    "    # Create an array from 0 -> total number of samples\n",
    "    all_idx = np.arange(0, move_history_input.shape[0], 1)\n",
    "\n",
    "    # Randomly shuffle the index's (Just the array we created, not the actual data)\n",
    "    np.random.shuffle(all_idx)\n",
    "\n",
    "    # Assign training/validation/evaluation index's\n",
    "    train_idx = all_idx[:num_train]\n",
    "    val_idx = all_idx[num_train: num_train + num_val]\n",
    "    eval_idx = all_idx[num_train + num_val:]\n",
    "\n",
    "    # Create Training/Validation/Evaluation Data by assigning the data from Move_History at each index\n",
    "    train_input_data, train_output_data = move_history_input[train_idx], move_history_output[train_idx]\n",
    "    val_input_data, val_output_data = move_history_input[val_idx], move_history_output[val_idx]\n",
    "    eval_input_data, eval_output_data = move_history_input[eval_idx], move_history_output[eval_idx]\n",
    "\n",
    "    print('Training Samples = {}, Validation Samples = {}, Evaluation Samples = {}'.format(train_input_data.shape[0], val_input_data.shape[0], eval_input_data.shape[0]))\n",
    "    return train_input_data, train_output_data, val_input_data, val_output_data, eval_input_data, eval_output_data\n",
    "\n",
    "def split_into_batches(train_in_data, train_out_data, batch_size):\n",
    "\n",
    "    num_batches = int(np.floor(train_in_data.shape[0]/batch_size))\n",
    "\n",
    "    train_in_batches = np.zeros((num_batches, batch_size, train_in_data.shape[1], train_in_data.shape[2]))\n",
    "    train_out_batches = np.zeros((num_batches, batch_size, train_out_data.shape[1]))\n",
    "\n",
    "    samples = np.arange(0, num_batches * batch_size, step=1)\n",
    "    np.random.shuffle(samples)\n",
    "\n",
    "    for i in range(train_in_batches.shape[0]):\n",
    "        start_num = i * batch_size\n",
    "        end_num = start_num + batch_size\n",
    "\n",
    "        batch_samples = samples[start_num:end_num]\n",
    "\n",
    "        train_in_batches[i] = train_in_data[batch_samples]\n",
    "        train_out_batches[i] = train_out_data[batch_samples]\n",
    "\n",
    "    return train_in_batches, train_out_batches\n",
    "\n",
    "# Folder Paths\n",
    "data_load_folder = 'C:/Users/Jordan Yeomans/Documents/GitHub/RiddlesIO/four_in_a_row/Data/Processed_Data/Random_vs_Random/'\n",
    "nn_save_folder = 'C:/Users/Jordan Yeomans/Documents/GitHub/RiddlesIO/four_in_a_row/NeuralNetworks/AI_Bot_Version_1/'\n",
    "\n",
    "# NN Parameters\n",
    "lr = 0.0001\n",
    "epochs = 1000\n",
    "val_split = 0.1\n",
    "eval_split = 0.05\n",
    "batch_size = 1024\n",
    "\n",
    "# Load Data\n",
    "move_history_input = np.load(data_load_folder + 'input_data.npy')\n",
    "move_history_output = np.load(data_load_folder + 'output_data.npy')\n",
    "\n",
    "# Check Number Of Samples\n",
    "print('Input Data Shape = {}:'.format(move_history_input.shape))\n",
    "print('Output Data Shape = {}:'.format(move_history_output.shape))\n",
    "\n",
    "# Reshape output to shape (7, )\n",
    "move_history_output = move_history_output.reshape(move_history_output.shape[0], move_history_output.shape[1])\n",
    "\n",
    "# Look at an example Input/Output\n",
    "print(move_history_output[9])\n",
    "plot_winner_board(move_history_input[9])\n",
    "\n",
    "# Split data into training, validation and evaluation\n",
    "train_in_data, train_out_data, val_in_data, val_out_data, eval_in_data, eval_out_data = split_data(move_history_input, move_history_output, val_split, eval_split)\n",
    "\n",
    "# Create Placeholders\n",
    "x = tf.placeholder(tf.float32, shape=[None, 6, 7], name='input_placeholder')\n",
    "y = tf.placeholder(tf.float32, shape=[None, 7], name='output_placeholder')\n",
    "\n",
    "# Create Network\n",
    "nn = tf.layers.flatten(x, name='input')                 # Flatten Board\n",
    "nn = tf.layers.dense(nn, 256, activation=tf.nn.relu)    # Layer 1 - Fully Connected with 256 Nodes\n",
    "nn = tf.layers.dense(nn, 256, activation=tf.nn.relu)    # Layer 2 - Fully Connected with 256 Nodes\n",
    "nn = tf.layers.dense(nn, 256, activation=tf.nn.relu)    # Layer 3 - Fully Connected with 256 Nodes\n",
    "last_layer = tf.layers.dense(nn, 7, name='output')      # Output Layer\n",
    "\n",
    "# Define Loss Function\n",
    "loss_function = tf.nn.softmax_cross_entropy_with_logits_v2(logits=last_layer, labels=y)\n",
    "loss = tf.reduce_mean(loss_function)\n",
    "\n",
    "# Create Optimiser\n",
    "learning_step = tf.train.AdamOptimizer(lr)\n",
    "optimiser = learning_step.minimize(loss)\n",
    "\n",
    "# Create Accuracy Evaluation\n",
    "correct = tf.equal(tf.argmax(last_layer, axis=1), tf.argmax(y, axis=1))\n",
    "acc = tf.reduce_mean(tf.cast(correct, 'float'))\n",
    "\n",
    "# Create Saver\n",
    "saver = tf.train.Saver()\n",
    "best_acc = 0\n",
    "\n",
    "# Train Network\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # Initialise Variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Iterate over all Epochs\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # Split training data into batches\n",
    "        train_in_batches, train_out_batches = split_into_batches(train_in_data, train_out_data, batch_size)\n",
    "\n",
    "        # Iterate over all batches\n",
    "        for batch in range(train_in_batches.shape[0]):\n",
    "\n",
    "            _, batch_cost = sess.run([optimiser, loss], feed_dict={x: train_in_batches[batch], y: train_out_batches[batch]})\n",
    "\n",
    "        # Evaluate Training and Validation Accuracy\n",
    "        epoch_train_acc = sess.run(acc, feed_dict={x: train_in_data, y: train_out_data})\n",
    "        epoch_val_acc = sess.run(acc, feed_dict={x: val_in_data, y: val_out_data})\n",
    "\n",
    "        # Save model if it is an improvement\n",
    "        if epoch_val_acc > best_acc:\n",
    "            best_acc = epoch_val_acc\n",
    "            saver.save(sess, nn_save_folder)\n",
    "            print('Saved Model')\n",
    "\n",
    "        # Print results every 10 epochs\n",
    "        if epoch % 10 == 0:\n",
    "            print('Single Batch Cost = {:.3f}, Train Acc = {:.3f}%, Val Acc = {:.3f}%'.format(batch_cost, epoch_train_acc * 100, epoch_val_acc * 100))\n",
    "\n",
    "    # Load Saved Session\n",
    "    saver.restore(sess, nn_save_folder)\n",
    "\n",
    "    # After Training, Check Evaluation Accuracy\n",
    "    eval_acc = sess.run(acc, feed_dict={x: eval_in_data, y: eval_out_data})\n",
    "    print('Evaluation Acc = {:.3f}%'.format(eval_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
