{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Learns to Play Connect 4\n",
    "#### Jordan Yeomans - 2018\n",
    "\n",
    "## Part 6 - Implement AI Version 1\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "At this point we have trained a Neural Network to predict the move of the winning player with 50% accuracy. Let's see if the bot can use what it's learnt to play (and hopefully win) against the same bot it was playing before\n",
    "\n",
    "We need to do two things:\n",
    "\n",
    "1. Update the State object to include a few parameters\n",
    "2. Update the make_move function\n",
    "\n",
    "#### Step 1 - Add Parameters To The State() Object\n",
    "\n",
    "For simplicity I am using the State object to hold the store the placeholders and model. We can then call on this object each itteration.\n",
    "\n",
    "1. Include the filepath to the saved model\n",
    "2. Create x placeholder\n",
    "3. Create Network (Needs to be the same as what has been trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(object):\n",
    "    def __init__(self):\n",
    "        self.settings = Settings()\n",
    "        self.field = Field()\n",
    "        self.round = 0\n",
    "\n",
    "        folder = 'C:/Users/Jordan Yeomans/Documents/GitHub/RiddlesIO/four_in_a_row/Data/Raw_Data/AI-v1_vs_Random/Red_AI-v1/'\n",
    "        num_files = os.listdir(folder)\n",
    "        self.name = folder + str(len(num_files)+1) + '.npy'\n",
    "        self.first = None\n",
    "\n",
    "        self.model_folder = 'C:/Users/Jordan Yeomans/Documents/GitHub/RiddlesIO/four_in_a_row/NeuralNetworks/AI_Bot_Version_1/'\n",
    "\n",
    "        self.x = tf.placeholder(tf.float32, shape=[None, 6, 7], name='input_placeholder')\n",
    "        \n",
    "        nn = tf.layers.flatten(self.x, name='input')\n",
    "        nn = tf.layers.dense(nn, 256, activation=tf.nn.relu)\n",
    "        nn = tf.layers.dense(nn, 256, activation=tf.nn.relu)\n",
    "        nn = tf.layers.dense(nn, 256, activation=tf.nn.relu)\n",
    "        self.last_layer = tf.layers.dense(nn, 7, name='output')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2 - Update make_move() function\n",
    "\n",
    "Unlike in the first bot, which had some long logic to figure out who's turn it was and what a winning move might be, we have scrapped all of that.\n",
    "\n",
    "Now the simple question is:\n",
    "\n",
    "- Given this board, what column should we place the token in?\n",
    "\n",
    "The enemy is the original bot, which includes the logic to calculate the winning moves. This mean's our AI-v1 has a bit of a disavantage. So to win, our network needs to have learnt what is a winning move while the opponent is being told what a winning move is!\n",
    "\n",
    "To implement the network:\n",
    "\n",
    "1. We need to make a saver object so we can resore the saved model\n",
    "2. We get the input data as the most recent board and reshape it to be of the shape (1, 6, 7). Remember our tensor is expecting a shape (None, 6, 7). It a bit of a trick, but None can't actually be \"None\", it needs to be something\n",
    "3. Start a session\n",
    "4. Restore the model\n",
    "5. Run the model (Note the state.last_layer is the model stored in the State object. Same applies for state.x which is the x placeholder stored in the state object)\n",
    "6. The move is the argmax of the output\n",
    "\n",
    "How simple is that!\n",
    "\n",
    "We continue to save the board so we can continue learning later!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_move(state):\n",
    "\n",
    "    field_state = np.array(state.field.field_state)\n",
    "\n",
    "    # Recording Data\n",
    "    if state.round == 0:\n",
    "        current_board = np.zeros((30, 6, 7))\n",
    "    else:\n",
    "        current_board = np.load(state.name)\n",
    "\n",
    "    # Get Most Recent Board\n",
    "    for row in range(6):\n",
    "        yellow_idx = np.where(field_state[row] == '1')[0]\n",
    "        red_idx = np.where(field_state[row] == '0')[0]\n",
    "\n",
    "        current_board[state.round][row][yellow_idx] = 1\n",
    "        current_board[state.round][row][red_idx] = -1\n",
    "\n",
    "    # Make Move from NN\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    input_data = current_board[state.round]\n",
    "    input_data = input_data.reshape([1, input_data.shape[0], input_data.shape[1]])\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "\n",
    "        saver.restore(sess, state.model_folder)\n",
    "\n",
    "        output = sess.run(state.last_layer, feed_dict={state.x: input_data})\n",
    "        move = np.argmax(output)\n",
    "\n",
    "    np.save(state.name, current_board)\n",
    "\n",
    "    return 'place_disc {}'.format(move)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3 - Run Some Games!\n",
    "\n",
    "Success! We are winning around 75% of games!\n",
    "\n",
    "Remember, Random vs Random 50% - 50% so this is definititely an improvement!\n",
    "\n",
    "That makes a bit of a checkpoint for us. We know we can:\n",
    "\n",
    "1. Run Games\n",
    "2. Store Games\n",
    "3. Organise Data\n",
    "4. Build and Train a NN\n",
    "5. Implement an NN\n",
    "6. Build an AI that has learnt something!\n",
    "\n",
    "Let's see how far we can go!\n",
    "\n",
    "Complete code is below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://i.imgur.com/oUsfFws.png\" width=\"1000\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML\n",
    "Image(url= \"https://i.imgur.com/oUsfFws.png\", width=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jordan yeomans\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import sys\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "class Settings(object):\n",
    "    def __init__(self):\n",
    "        self.timebank = None\n",
    "        self.time_per_move = None\n",
    "        self.player_names = None\n",
    "        self.your_bot = None\n",
    "        self.your_botid = None\n",
    "        self.field_width = None\n",
    "        self.field_height = None\n",
    "\n",
    "\n",
    "class Field(object):\n",
    "    def __init__(self):\n",
    "        self.field_state = None\n",
    "\n",
    "    def update_field(self, celltypes, settings):\n",
    "        self.field_state = [[] for _ in range(settings.field_height)]\n",
    "        n_cols = settings.field_width\n",
    "        for idx, cell in enumerate(celltypes):\n",
    "            row_idx = idx // n_cols\n",
    "            self.field_state[row_idx].append(cell)\n",
    "\n",
    "class State(object):\n",
    "    def __init__(self):\n",
    "        self.settings = Settings()\n",
    "        self.field = Field()\n",
    "        self.round = 0\n",
    "\n",
    "        folder = 'C:/Users/Jordan Yeomans/Documents/GitHub/RiddlesIO/four_in_a_row/Data/Raw_Data/AI-v1_vs_Random/Red_AI-v1/'\n",
    "        num_files = os.listdir(folder)\n",
    "        self.name = folder + str(len(num_files)+1) + '.npy'\n",
    "        self.first = None\n",
    "\n",
    "        self.model_folder = 'C:/Users/Jordan Yeomans/Documents/GitHub/RiddlesIO/four_in_a_row/NeuralNetworks/AI_Bot_Version_1/'\n",
    "\n",
    "        self.x = tf.placeholder(tf.float32, shape=[None, 6, 7], name='input_placeholder')\n",
    "        self.y = tf.placeholder(tf.float32, shape=[None, 7], name='output_placeholder')\n",
    "\n",
    "        nn = tf.layers.flatten(self.x, name='input')\n",
    "        nn = tf.layers.dense(nn, 256, activation=tf.nn.relu)\n",
    "        nn = tf.layers.dense(nn, 256, activation=tf.nn.relu)\n",
    "        nn = tf.layers.dense(nn, 256, activation=tf.nn.relu)\n",
    "        self.last_layer = tf.layers.dense(nn, 7, name='output')\n",
    "\n",
    "def parse_communication(text):\n",
    "    \"\"\" Return the first word of the communication - that's the command \"\"\"\n",
    "    return text.strip().split()[0]\n",
    "\n",
    "\n",
    "def settings(text, state):\n",
    "    \"\"\" Handle communication intended to update game settings \"\"\"\n",
    "    tokens = text.strip().split()[1:]  # Ignore token 0, it's the string \"settings\".\n",
    "    cmd = tokens[0]\n",
    "    if cmd in ('timebank', 'time_per_move', 'your_botid', 'field_height', 'field_width'):\n",
    "        # Handle setting integer settings.\n",
    "        setattr(state.settings, cmd, int(tokens[1]))\n",
    "    elif cmd in ('your_bot',):\n",
    "        # Handle setting string settings.\n",
    "        setattr(state.settings, cmd, tokens[1])\n",
    "    elif cmd in ('player_names',):\n",
    "        # Handle setting lists of strings.\n",
    "        setattr(state.settings, cmd, tokens[1:])\n",
    "    else:\n",
    "        raise NotImplementedError('Settings command \"{}\" not recognized'.format(text))\n",
    "\n",
    "\n",
    "def update(text, state):\n",
    "    \"\"\" Handle communication intended to update the game \"\"\"\n",
    "    tokens = text.strip().split()[2:] # Ignore tokens 0 and 1, those are \"update\" and \"game\" respectively.\n",
    "    cmd = tokens[0]\n",
    "    if cmd in ('round',):\n",
    "        # Handle setting integer settings.\n",
    "        setattr(state.settings, 'round', int(tokens[1]))\n",
    "    if cmd in ('field',):\n",
    "        # Handle setting the game board.\n",
    "        celltypes = tokens[1].split(',')\n",
    "        state.field.update_field(celltypes, state.settings)\n",
    "\n",
    "\n",
    "def action(text, state):\n",
    "    \"\"\" Handle communication intended to prompt the bot to take an action \"\"\"\n",
    "    tokens = text.strip().split()[1:] # Ignore token 0, it's the string \"action\".\n",
    "    cmd = tokens[0]\n",
    "    if cmd in ('move',):\n",
    "        move = make_move(state)\n",
    "        state.round += 1\n",
    "        return move\n",
    "    else:\n",
    "        raise NotImplementedError('Action command \"{}\" not recognized'.format(text))\n",
    "\n",
    "def make_move(state):\n",
    "\n",
    "    field_state = np.array(state.field.field_state)\n",
    "\n",
    "    # Recording Data\n",
    "    if state.round == 0:\n",
    "        current_board = np.zeros((30, 6, 7))\n",
    "    else:\n",
    "        current_board = np.load(state.name)\n",
    "\n",
    "    # Get Most Recent Board\n",
    "    for row in range(6):\n",
    "        yellow_idx = np.where(field_state[row] == '1')[0]\n",
    "        red_idx = np.where(field_state[row] == '0')[0]\n",
    "\n",
    "        current_board[state.round][row][yellow_idx] = 1\n",
    "        current_board[state.round][row][red_idx] = -1\n",
    "\n",
    "    # Make Move from NN\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    input_data = current_board[state.round]\n",
    "    input_data = input_data.reshape([1, input_data.shape[0], input_data.shape[1]])\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "\n",
    "        saver.restore(sess, state.model_folder)\n",
    "\n",
    "        output = sess.run(state.last_layer, feed_dict={state.x: input_data})\n",
    "        move = np.argmax(output)\n",
    "\n",
    "    np.save(state.name, current_board)\n",
    "\n",
    "    return 'place_disc {}'.format(move)\n",
    "\n",
    "def main():\n",
    "    command_lookup = { 'settings': settings, 'update': update, 'action': action }\n",
    "    state = State()\n",
    "\n",
    "\n",
    "    for input_msg in sys.stdin:\n",
    "        cmd_type = parse_communication(input_msg)\n",
    "        command = command_lookup[cmd_type]\n",
    "\n",
    "        # Call the correct command.\n",
    "        res = command(input_msg, state)\n",
    "\n",
    "        # Assume if the command generates a string as output, that we need\n",
    "        # to \"respond\" by printing it to stdout.\n",
    "        if isinstance(res, str):\n",
    "            print(res)\n",
    "            sys.stdout.flush()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
